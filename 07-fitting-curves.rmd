# Fitting curves

### In brief

> So far all our regression models have assumed that our variables have
> **_linear relationships_**. That isn't always the case, and sometimes we need
> to fit curved lines to describe the relationship of predictors and outcomes.
> As we saw before, fitting curved lines has costs as well as benefits: A curved
> line is more likely to **overfit** the data, and may be less good at
> predicting new data. But for some models curved lines are essential to
> describe the world as it really is.


```{r, echo=F, include=F}
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE, cache=TRUE, comment=">", message=FALSE)
library(tidyverse)
library(webex)
library(pander)
theme_set(theme_minimal())
```

\

## Using polynomials to fit curves

-   [**Slides from the session**](slides/regression3-chris.ppt) (available 02-02-2020)

\

### Overview



In this session we will:

- See how we can add *polynomial terms* such as $x^2$, $x^3$ to a regression model to capture non-linear relationships.

- Use ANOVA and Bayes Factors to determine whether these terms improve the model.


You should be comfortable with what we did in the previous Building Models 1 and Building Models 2 sessions before attempting this one.



